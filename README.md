# Get started

To get started:

create .env with OPENAI_API_KEY

`yarn install`

`node evals.js`

The eval in eals/eval-001 will be run ten times. The results will be saved to ./output.

# Eval structure

Each eval contains:

- app: The codebase before transformation.
- prompt.py: A description of the transformation to be made.
- solution: The canonical solution with the complete codebase transformed.

# Purpose

Using integration tests, you can automate the testing of your agent or run Monte Carlo simulations.

<img width="1041" alt="Screenshot 2023-06-26 at 2 48 17 PM" src="https://github.com/jamesmurdza/agenteval/assets/33395784/26f416f8-b803-402c-8abe-6b5bca9bc253">

# Demo

https://github.com/jamesmurdza/agenteval/assets/33395784/738f9dff-bfbb-4fd0-a1ba-c451f57cc32e

